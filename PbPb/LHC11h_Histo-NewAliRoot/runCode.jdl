Jobtag = {
   "comment:Automatically generated analysis JDL"
};
# Input xml collections
InputDataCollection = {
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/$1,nodownload"
};
# Output directory
OutputDir = "/alice/cern.ch/user/j/jisong//11h_newAliroot_test/output/$2/#alien_counter_03i#";
# List of requested packages
Packages = {
   "VO_ALICE@AliRoot::vAN-20141102",
   "VO_ALICE@ROOT::v5-34-08-6",
   "VO_ALICE@APISCONFIG::V1.1x"
};
# List of input files to be uploaded to workers
InputFile = {
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/GeneratedMacro.C",
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/analysis.root",
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/AliXiStarEventCollection.h",
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/AliXiStarEventCollection.cxx",
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/AliXiStar.h",
   "LF:/alice/cern.ch/user/j/jisong/11h_newAliroot_test/AliXiStar.cxx"
};
# This is the startup script
Executable = "/alice/cern.ch/user/j/jisong/11h_newAliroot_test/analysis.sh";
# We split per SE or file
Split = "se";
# Time after which the job is killed (666 min.)
TTL = "40000";
# Resubmit failed jobs until DONE rate reaches this percentage
MasterResubmitThreshold = "97%";
# Maximum number of input files to be processed per subjob
SplitMaxInputFileNumber = "50";
# Format of input data
InputDataListFormat = "xml-single";
# Collection name to be processed on each worker node
InputDataList = "wn.xml";
# List of output files and archives
Output = {
   "log_archive.zip:std*@disk=1",
   "root_archive.zip:EventStat_temp.root,MyOutput.root,*.stat@disk=2"
};
# AliEn price for this job
Price = "1";
# Validation script to be run for each subjob
Validationcommand = "/alice/cern.ch/user/j/jisong/11h_newAliroot_test/analysis_validation.sh";
User = "jisong";

# JDL variables
JDLVariables = 
{
   "Packages",
   "OutputDir"
};
Workdirectorysize = {"5000MB"};
